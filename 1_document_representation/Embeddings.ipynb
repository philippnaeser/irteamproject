{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "### Please run this after running tfidf, we need those values to weight the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "tfidf=pd.read_pickle('pickle/tfidf.pkl')\n",
    "inverted_index = pd.read_pickle('../0_Collection_and_Inverted_Index/pickle/inverted_index.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further information to the embeddings can be found in Word Embeddings Experiments.ipynb, here we only use the parts for feature generation.\n",
    "\n",
    "We use two versions of embeddings here, fasttext and fasttext.word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5371"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "# Gensim requires list of lists of Unicode 8 strings as an input. Since we have a small collection, \n",
    "# we are fine with loading everything into memory.\n",
    "import re\n",
    "doc_list= []\n",
    "with open('../nfcorpus/raw/doc_dump.txt', 'r', encoding='utf-8') as rf1:\n",
    "    for line in rf1:\n",
    "        l = re.sub(\"MED-.*\\t\", \"\",line).lower().strip('\\n').split()\n",
    "        doc_list.append(l) \n",
    "len(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.models.fasttext.FAST_VERSION > -1 # make sure that you are using Cython backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run this to create a fasttext model of our documents\n",
    "#fasttext= gensim.models.FastText(bigram[doc_list], min_count= 1, min_n= 3, max_n=12)\n",
    "fasttext= gensim.models.FastText(doc_list, min_count= 1, min_n= 3, max_n=12)\n",
    "fasttext.save('pickle/our_fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Same as above, run this to compute the model, or run next cell to load it (if it exists on disk already)\n",
    "word2vec= gensim.models.FastText(doc_list, min_count= 1, word_ngrams=0)\n",
    "word2vec.save('pickle/our_fasttextword2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you already ran the upper part, you can load the results here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To save time, load the models, if they already exist\n",
    "# this loads the whole model, (not only the vectors)\n",
    "fasttext = gensim.models.FastText.load('pickle/our_fasttext')\n",
    "word2vec = gensim.models.FastText.load('pickle/our_fasttextword2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hort    [0.420471, -1.27513, 1.113, -0.238618, 0.47387...\n",
       "+        [-0.230507, -0.354534, 0.174181, 0.363291, 0.5...\n",
       "-        [-0.346358, -0.279879, 0.261858, 0.355061, 0.4...\n",
       "--a      [-0.0193924, -0.354634, 0.208689, 0.0206046, 0...\n",
       "--all    [0.458753, -0.815639, -0.0254263, 0.274309, 0....\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fasttext Embeddings, 100-d dense vector\n",
    "fasttext_embeddings_list=[]\n",
    "words_not_covered_in_fasttext=[]\n",
    "for word in inverted_index.index:\n",
    "    try:\n",
    "        fasttext_embeddings_list.append(fasttext.wv.get_vector(word))\n",
    "    except:\n",
    "        words_not_covered_in_fasttext.append(word)\n",
    "        fasttext_embeddings_list.append(np.zeros(100)) # for those 3 OOV we insert an array consisting of zeros\n",
    "fasttext_embeddings=pd.Series(fasttext_embeddings_list,index=inverted_index.index)\n",
    "fasttext_embeddings.to_pickle('pickle/fasttext_embeddings.pkl')\n",
    "fasttext_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hort    [-2.15808, -0.929237, 0.76162, 0.0194782, -0.8...\n",
       "+        [-0.319704, -0.0608469, -0.312795, 0.625708, -...\n",
       "-        [-0.374173, -0.235332, -0.46186, 0.581642, -0....\n",
       "--a      [-0.252248, -0.0543773, 0.108192, 0.0346592, -...\n",
       "--all    [-0.0988697, -0.412766, -0.526214, -0.416635, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word2Vec Embeddings, 100-d dense vector\n",
    "word2vec_embeddings_list=[]\n",
    "words_not_covered_in_word2vec=[]\n",
    "for word in inverted_index.index:\n",
    "    try:\n",
    "        word2vec_embeddings_list.append(word2vec.wv.get_vector(word))\n",
    "    except:\n",
    "        words_not_covered_in_word2vec.append(word)\n",
    "        word2vec_embeddings_list.append(np.zeros(100)) # for those 3 OOV we insert an array consisting of zeros\n",
    "word2vec_embeddings=pd.Series(word2vec_embeddings_list,index=inverted_index.index)\n",
    "word2vec_embeddings.to_pickle('pickle/word2vec_embeddings.pkl')\n",
    "word2vec_embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another shortcut here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fasttext_embeddings = pd.read_pickle('pickle/fasttext_embeddings.pkl')\n",
    "word2vec_embeddings = pd.read_pickle('pickle/word2vec_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weighted_embeddings(embeddings, tfidf_embed):\n",
    "    sum_of_tfidf_weights=tfidf_embed.sum(axis=0)#vector containing the normalizing constant for each doc\n",
    "    embeddings_dict={}\n",
    "    # we have to make use of the following workaround to avoid memory errors\n",
    "    # 1. calculate 100d embeddings vector for each doc/query and store it in dictionary\n",
    "    # 2. recreate a a dataframe containg the embeddings for all docs/queries from the dictionary\n",
    "    for doc in tfidf_embed.columns:\n",
    "        if doc not in embeddings_dict.keys():\n",
    "            embedding=(tfidf_embed[doc].mask(tfidf_embed[doc]!=0, other=(tfidf_embed[doc]*embeddings)).sum(axis=0))/sum_of_tfidf_weights[doc]\n",
    "            embeddings_dict[doc]=embedding\n",
    "        else:\n",
    "            print('calculated embeddings successfully and stored them in dictionary')\n",
    "    weighted_embedding = pd.DataFrame.from_dict(embeddings_dict)\n",
    "    return weighted_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_fasttext = get_weighted_embeddings(fasttext_embeddings, tfidf)\n",
    "\n",
    "#Let's save those again, as computing them might take a while\n",
    "documents_fasttext.to_pickle('pickle/documents_fasttext.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_word2vec= get_weighted_embeddings(word2vec_embeddings, tfidf)\n",
    "\n",
    "#Save them as well\n",
    "documents_word2vec.to_pickle('pickle/documents_word2vec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
