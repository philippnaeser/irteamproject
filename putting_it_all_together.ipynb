{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Putting it all together\n",
    "\n",
    "## 1: Creating the collection and vocabulary\n",
    "\n",
    "Import *collection_vocabulary.py* and create an instance of the collection class. Its attributes are the collection itself, the vocabulary, and some descriptive summary statistics (e.g. vocabulary size, collection size, collection length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collection_vocabulary import Collection\n",
    "col=Collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix=[]\n",
    "for doc in col.collection:\n",
    "    tf_vector =[]\n",
    "    for word in col.vocabulary:\n",
    "        n= col.collection[doc].count(word)\n",
    "        tf_vector.append(n)\n",
    "    doc_term_matrix.append(tf_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Creating the document term matrix\n",
    "The document term matrix is obtained as a lists of lists from the collection created in step 1. It is then converted to a Pandas dataframe, which is stored to disk to facilitate debugging, and further experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "doc_term_matrix= pd.DataFrame(data=doc_term_matrix,index= col.collection.keys(),columns=col.vocabulary)\n",
    "doc_term_matrix.to_pickle('doc_term_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'hort</th>\n",
       "      <th>+</th>\n",
       "      <th>-</th>\n",
       "      <th>--a</th>\n",
       "      <th>--all</th>\n",
       "      <th>--have</th>\n",
       "      <th>--mainly</th>\n",
       "      <th>--of</th>\n",
       "      <th>--showed</th>\n",
       "      <th>--the</th>\n",
       "      <th>...</th>\n",
       "      <th>zooplankton</th>\n",
       "      <th>zoxazolamine</th>\n",
       "      <th>zr</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuccarini</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zugesetztem</th>\n",
       "      <th>zusatzstoffe-online</th>\n",
       "      <th>zygote</th>\n",
       "      <th>zymography</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MED-10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MED-14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MED-118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29052 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         'hort  +  -  --a  --all  --have  --mainly  --of  --showed  --the  \\\n",
       "MED-10       0  0  0    0      0       0         0     0         0      0   \n",
       "MED-14       0  0  0    0      0       0         0     0         0      0   \n",
       "MED-118      0  0  0    0      0       0         0     0         0      0   \n",
       "\n",
       "            ...      zooplankton  zoxazolamine  zr  zu  zuccarini  zucchini  \\\n",
       "MED-10      ...                0             0   0   0          0         0   \n",
       "MED-14      ...                0             0   0   0          0         0   \n",
       "MED-118     ...                0             0   0   0          0         0   \n",
       "\n",
       "         zugesetztem  zusatzstoffe-online  zygote  zymography  \n",
       "MED-10             0                    0       0           0  \n",
       "MED-14             0                    0       0           0  \n",
       "MED-118            0                    0       0           0  \n",
       "\n",
       "[3 rows x 29052 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix.head(3) # this is how the doc term matrix looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check: Assure that each doc contains at least one term, i.e. there are no empty docs\n",
    "doc_term_matrix.sum(axis=1).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some more summary stats for our project report\n",
    "doc_term_matrix.sum(axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix.sum(axis=1).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good point to start off the actual analysis and calculate different retrieval models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TF-IDF\n",
    "\n",
    "### IDF\n",
    "\n",
    "Let's start with the easier part: calcualating inverse document frequencies and storing them in a data frame. The index of all dataframes being produced in the remainder of this notebook will be the vocabulary ('the inverted index'), which allows applying the different retrieval models and querying the collection in a standardized way.\n",
    "\n",
    "We will fix and use the parameters of the different models as discussed in the lecture. This may be subject to further hyperparameter tuning (bear in mind we are 'learning to rank.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index= doc_term_matrix.transpose()\n",
    "inverted_index.to_pickle('inverted_index.pkl') # let's also store the inverted index to disk\n",
    "def greater_than_zero(some_value): return some_value > 0\n",
    "def calculate_idf(some_value): return np.log10(col.collection_size/some_value)\n",
    "idf=df.apply(calculate_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check 1\n",
    "# each term should occur at least once (implied by the way we construct the index), hence min>=1\n",
    "inverted_index.sum(axis=1).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF\n",
    "\n",
    "Raw term frequency is what we already have when we look columnwise at the  *inverted_index* dataframe.\n",
    "As discussed in the lecture, we will normalize this frequency by dividing with the raw frequency of the most frequent term in each document. Next, we then take the logarithm (any logarithm will do the job) since we assume that relevance does not increase linearly with term frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d071503/miniconda2/envs/mycondaenv/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log10\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#TODO: double-check this with slides 14 and 19 of lecture 4, \n",
    "most_frequent_term=inverted_index.max(axis=0) # determine most frequent term in each doc\n",
    "tf= (1+ np.log10(inverted_index)).div(np.log10(1+ most_frequent_term),axis=1)\n",
    "tf.replace([np.inf, -np.inf], 0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF\n",
    "Bringing the pieces together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf= tf.mul(idf, axis=0) # we multiply the tf scores in every doc with the corresponding idf scores\n",
    "tfidf.to_pickle('tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MED-10</th>\n",
       "      <th>MED-14</th>\n",
       "      <th>MED-118</th>\n",
       "      <th>MED-301</th>\n",
       "      <th>MED-306</th>\n",
       "      <th>MED-329</th>\n",
       "      <th>MED-330</th>\n",
       "      <th>MED-332</th>\n",
       "      <th>MED-334</th>\n",
       "      <th>MED-335</th>\n",
       "      <th>...</th>\n",
       "      <th>MED-938</th>\n",
       "      <th>MED-939</th>\n",
       "      <th>MED-940</th>\n",
       "      <th>MED-892</th>\n",
       "      <th>MED-906</th>\n",
       "      <th>MED-917</th>\n",
       "      <th>MED-941</th>\n",
       "      <th>MED-942</th>\n",
       "      <th>MED-952</th>\n",
       "      <th>MED-961</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "      <td>29052.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.003638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.082391</td>\n",
       "      <td>0.077375</td>\n",
       "      <td>0.069604</td>\n",
       "      <td>0.136185</td>\n",
       "      <td>0.105349</td>\n",
       "      <td>0.157469</td>\n",
       "      <td>0.097023</td>\n",
       "      <td>0.112068</td>\n",
       "      <td>0.100331</td>\n",
       "      <td>0.123847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116824</td>\n",
       "      <td>0.120984</td>\n",
       "      <td>0.111506</td>\n",
       "      <td>0.092023</td>\n",
       "      <td>0.123315</td>\n",
       "      <td>0.110750</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119924</td>\n",
       "      <td>0.102378</td>\n",
       "      <td>0.072841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.600756</td>\n",
       "      <td>3.083144</td>\n",
       "      <td>3.279604</td>\n",
       "      <td>6.749227</td>\n",
       "      <td>3.851621</td>\n",
       "      <td>5.952586</td>\n",
       "      <td>4.407110</td>\n",
       "      <td>4.553026</td>\n",
       "      <td>5.226977</td>\n",
       "      <td>5.921194</td>\n",
       "      <td>...</td>\n",
       "      <td>4.655919</td>\n",
       "      <td>6.681074</td>\n",
       "      <td>3.977361</td>\n",
       "      <td>5.347780</td>\n",
       "      <td>7.100402</td>\n",
       "      <td>4.240363</td>\n",
       "      <td>5.921194</td>\n",
       "      <td>6.090362</td>\n",
       "      <td>6.658925</td>\n",
       "      <td>2.740518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 3633 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MED-10        MED-14       MED-118       MED-301       MED-306  \\\n",
       "count  29052.000000  29052.000000  29052.000000  29052.000000  29052.000000   \n",
       "mean       0.004152      0.003803      0.002935      0.006350      0.005710   \n",
       "std        0.082391      0.077375      0.069604      0.136185      0.105349   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        3.600756      3.083144      3.279604      6.749227      3.851621   \n",
       "\n",
       "            MED-329       MED-330       MED-332       MED-334       MED-335  \\\n",
       "count  29052.000000  29052.000000  29052.000000  29052.000000  29052.000000   \n",
       "mean       0.008275      0.004693      0.006380      0.004965      0.006263   \n",
       "std        0.157469      0.097023      0.112068      0.100331      0.123847   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        5.952586      4.407110      4.553026      5.226977      5.921194   \n",
       "\n",
       "           ...            MED-938       MED-939       MED-940       MED-892  \\\n",
       "count      ...       29052.000000  29052.000000  29052.000000  29052.000000   \n",
       "mean       ...           0.005649      0.006764      0.006286      0.004697   \n",
       "std        ...           0.116824      0.120984      0.111506      0.092023   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "max        ...           4.655919      6.681074      3.977361      5.347780   \n",
       "\n",
       "            MED-906       MED-917       MED-941       MED-942       MED-952  \\\n",
       "count  29052.000000  29052.000000  29052.000000  29052.000000  29052.000000   \n",
       "mean       0.005315      0.004602      0.005860      0.004637      0.004089   \n",
       "std        0.123315      0.110750      0.118862      0.119924      0.102378   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        7.100402      4.240363      5.921194      6.090362      6.658925   \n",
       "\n",
       "            MED-961  \n",
       "count  29052.000000  \n",
       "mean       0.003638  \n",
       "std        0.072841  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        2.740518  \n",
       "\n",
       "[8 rows x 3633 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29052, 3633)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO (not part of the project): Think about storing this index as a real inverted index which may be used for look-up (e.g. Python dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unigram LM with Jelinek-Mercer-Smoothing\n",
    "Let's start where we always start off: generating/importing the inverted index and generating an instance of the collection class which already provides us with certain summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Language Model\n",
    "We want to find out how likely each word is if we look at the whole corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_LM=inverted_index.sum(axis=1)/col.collection_length # equal: inverted_index.sum(axis=1)/inverted_index.sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Language Models\n",
    "We want to obtain a language model for each document in the collection, therefore we look at the columns of the *inverted_index* dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_LMs=inverted_index/inverted_index.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3632.9999999999995"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check: Probabilities should sum columnwise to 1, and adding all columns should yield the collection size (3638)\n",
    "local_LM.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram LM with J-M-Smoothing\n",
    "As introduced in the lecture, this smoothing scheme assigns equal weights to the global and local LMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_LM= (local_LM.apply(lambda x: x+ global_LM)).apply(lambda x: x/2)# same as multiplying both by 0.5\n",
    "unigram_LM.to_pickle('unigramLM.pkl')#writing Unigram-LM to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3633.0000000010787"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check: probabilities in every doc should sum up to one and all docs should sum up tp 3633\n",
    "unigram_LM.sum().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. BIM 25\n",
    "Let's approach BIM25 step by step, which means modeling the BIM and then gradually extending it. \n",
    "We start from the naive assumption that we do not have any relevance feedbacks.\n",
    "\n",
    "\n",
    "### BIM \n",
    "This simplification results in the following formula we want to compute:\n",
    "w_t= log(0.5 * N/N_t)\n",
    "\n",
    "N_t signifies in how many documents an term appears. This is what we already calucalted as the 'raw' document frequency in the TfIdf-model above. \n",
    "What we are basically doing is multiplying the raw inverse document frequency by 0.5 and then taking the logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIM=df.apply(lambda x: col.collection_size/x).apply(lambda x: x*0.5).apply(lambda x: np.log10(x))\n",
    "#TODO: Ask Robert/Goran about base of logarithm\n",
    "#In Okapi BIM 25, no multiplcation with 0.5 according to this site: https://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Discuss this: Interesting observation: in BIM 25 weights may actually become negative\n",
    "sum(BIM<0) # hence we are adding term weights this seems okay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIM 25\n",
    "Let's focus on the weighting part and then multiply these weights with the BIM from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters as presented in the lecture\n",
    "k=1.5\n",
    "b=0.25\n",
    "document_lenght= inverted_index.sum()\n",
    "average_document_length= col.collection_length/col.collection_size # 146.20478943022295 TODO: include in project report\n",
    "doc_len_div_by_avg_doc_len= document_lenght.apply(lambda x: x/average_document_length)\n",
    "#sanity check, should yield 3633\n",
    "doc_len_div_by_avg_doc_len.sum() == 3633\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighting_bim25_nominator= inverted_index.apply(lambda x: x*(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the denominator is the tricky part since we have to add scalars and a vector to each column in the inverted index at the sa,e time\n",
    "weighting_bim25_denominator=inverted_index.add((doc_len_div_by_avg_doc_len*k*b), axis=1)+(k*(1-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging nominator and denominator\n",
    "weighting_bim25= weighting_bim25_nominator.div(weighting_bim25_denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29052, 3633)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check: 29052, 3633 ?\n",
    "weighting_bim25.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the weights, and the vanilla BIM from above, we can now construct BIM25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIM25=weighting_bim25.mul(BIM, axis=0)\n",
    "BIM25.to_pickle('BIM25.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Querying\n",
    "\n",
    "@Philipp Naeser: please look at *query.py* which already specifies in a class how a query should look like.\n",
    "Actually it may make sense to reinvert the inverted index, so you can pick the tfidf value columnwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample single term queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the same single term query  - \"cancer\". And compare the results of the three retrieval models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MED-3717    1.897206\n",
       "MED-1414    1.897206\n",
       "MED-3729    1.706995\n",
       "MED-4534    1.594690\n",
       "MED-4465    1.594690\n",
       "MED-2067    1.594690\n",
       "MED-2577    1.594690\n",
       "MED-2435    1.519069\n",
       "MED-4470    1.519069\n",
       "MED-2439    1.519069\n",
       "Name: cancer, dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TFIDF\n",
    "a= tfidf.loc['cancer'].sort_values(ascending=False).head(10) # if you transpose you can directly select by the index term  > tf.transpose().cancer\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MED-3703    0.081339\n",
       "MED-2137    0.061650\n",
       "MED-2174    0.057772\n",
       "MED-4391    0.052210\n",
       "MED-890     0.048745\n",
       "MED-5184    0.048281\n",
       "MED-3551    0.047909\n",
       "MED-3555    0.047347\n",
       "MED-2258    0.045462\n",
       "MED-3699    0.044962\n",
       "Name: cancer, dtype: float64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unigram LM\n",
    "b= unigram_LM.loc['cancer'].sort_values(ascending=False).head(10)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MED-3703    0.917499\n",
       "MED-1721    0.895649\n",
       "MED-2760    0.894057\n",
       "MED-3699    0.892689\n",
       "MED-3555    0.884759\n",
       "MED-14      0.881640\n",
       "MED-4928    0.880848\n",
       "MED-5353    0.877033\n",
       "MED-4050    0.876367\n",
       "MED-4785    0.876234\n",
       "Name: cancer, dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= BIM25.loc['cancer'].sort_values(ascending=False).head(10)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, there is very little overlap in th top 10 retrieved documents. Only the top-ranked doc of the probabilisitic ranking models matches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
